{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "## Start a Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"demographics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# import SparkFiles\n",
    "from pyspark import SparkFiles\n",
    "url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/demographics.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "# read in the csv file\n",
    "df = spark.read.csv(SparkFiles.get(\"demographics.csv\"), sep=\",\", header=True)\n",
    "df.show()\n",
    "\n",
    "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
    "| id|                name|age|height_meter|weight_kg|children|        occupation|academic_degree|salary|     location|\n",
    "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
    "|  0|       Darlena Avila| 58|        1.87|       53|       1|     Choreographer|            PhD|    68| South Dakota|\n",
    "|  1|            Yan Boyd| 65|         1.8|       40|       0|         Cellarman|       Bachelor|    73|     Delaware|\n",
    "|  2|         Joette Lane| 32|         1.8|       73|       1|Veterinary Surgeon|         Master|    69| South Dakota|\n",
    "|  3|        Jazmine Hunt| 61|        1.79|       89|       0|            Hawker|            PhD|    88|    Louisiana|\n",
    "|  4|      Remedios Gomez| 23|        1.64|       51|       2|     Choreographer|       Bachelor|    83|West Virginia|\n",
    "|  5|        Myung Brewer| 20|        1.68|       60|       4|    Window Dresser|       Bachelor|    65| South Dakota|\n",
    "|  6|         Shaun Lynch| 31|        1.56|       62|       0|            Weaver|         Master|    72|    Louisiana|\n",
    "|  7|     Melodi Mcdowell| 56|         1.6|       42|       0| Lighthouse Keeper|         Master|    65|    Louisiana|\n",
    "|  8|Charlesetta Steve...| 30|        1.62|       44|       3|        Millwright|         Master|    87|    Louisiana|\n",
    "|  9|       Merri Charles| 44|        1.69|       51|       5|  Medical Supplier|            PhD|    72|West Virginia|\n",
    "| 10|        Cassi Meyers| 55|        1.82|       72|       5|        Manicurist|       Bachelor|    73| South Dakota|\n",
    "| 11|      Shawnee Harmon| 66|        1.63|       78|       5| Medical Physicist|            PhD|    90|     Delaware|\n",
    "| 12|       Lyndia Spears| 62|        1.88|       41|       1|         Assistant|         Master|    78|       Alaska|\n",
    "| 13|          Page Evans| 35|        1.53|       74|       5|         Paramedic|       Bachelor|    69|     Delaware|\n",
    "| 14|        Telma Hebert| 66|        1.94|       79|       3|       Genealogist|         Master|    75| South Dakota|\n",
    "| 15|      Edelmira Drake| 23|        1.87|       72|       2|           Servant|            PhD|    77| South Dakota|\n",
    "| 16|       Oscar Guthrie| 40|        1.61|       46|       4| Technical Liaison|       Bachelor|    76|    Louisiana|\n",
    "| 17|   Bernardina Strong| 34|        1.55|       78|       1|         Scientist|            PhD|    90| South Dakota|\n",
    "| 18|        Caprice Hart| 64|        1.69|       67|       4|   Market Research|            PhD|    79|    Louisiana|\n",
    "| 19|         Alleen Pace| 25|        1.86|       81|       4|  Medical Supplier|            PhD|    77| South Dakota|\n",
    "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "## Print the column names\n",
    "df.columns\n",
    "\n",
    "['id',\n",
    " 'name',\n",
    " 'age',\n",
    " 'height_meter',\n",
    " 'weight_kg',\n",
    " 'children',\n",
    " 'occupation',\n",
    " 'academic_degree',\n",
    " 'salary',\n",
    " 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Print out the first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Select the columns & use describe to show the summary statistics\n",
    "df.select([\"age\", \"height_meter\", \"weight_kg\"]).describe().show()\n",
    "\n",
    "+-------+------------------+------------------+------------------+\n",
    "|summary|               age|      height_meter|         weight_kg|\n",
    "+-------+------------------+------------------+------------------+\n",
    "|  count|              1000|              1000|              1000|\n",
    "|   mean|            42.933|1.7519499999999995|            64.011|\n",
    "| stddev|14.255445581556843|0.1436897499623555|15.005733939099779|\n",
    "|    min|                18|               1.5|                38|\n",
    "|    max|                67|               2.0|                90|\n",
    "+-------+------------------+------------------+------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Print the schema to see the types\n",
    "df.printSchema()\n",
    "\n",
    "root\n",
    " |-- id: string (nullable = true)\n",
    " |-- name: string (nullable = true)\n",
    " |-- age: string (nullable = true)\n",
    " |-- height_meter: string (nullable = true)\n",
    " |-- weight_kg: string (nullable = true)\n",
    " |-- children: string (nullable = true)\n",
    " |-- occupation: string (nullable = true)\n",
    " |-- academic_degree: string (nullable = true)\n",
    " |-- salary: string (nullable = true)\n",
    " |-- location: string (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Rename the Salary column to `Salary (1k)` and show only this new column\n",
    "df = df.withColumnRenamed('Salary', 'Salary (1k)')\n",
    "df.select(\"Salary (1k)\").show(5)\n",
    "\n",
    "+-----------+\n",
    "|Salary (1k)|\n",
    "+-----------+\n",
    "|         68|\n",
    "|         73|\n",
    "|         69|\n",
    "|         88|\n",
    "|         83|\n",
    "+-----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Create a new column called `Salary` where the values are the `Salary (1k)` * 1000\n",
    "# Show the columns `Salary` and `Salary (1k)`\n",
    "df = df.withColumn(\"Salary\", df[\"Salary (1k)\"] * 1000)\n",
    "df.select([\"Salary\", \"Salary (1k)\"]).show(5)\n",
    "\n",
    "+-------+-----------+\n",
    "| Salary|Salary (1k)|\n",
    "+-------+-----------+\n",
    "|68000.0|         68|\n",
    "|73000.0|         73|\n",
    "|69000.0|         69|\n",
    "|88000.0|         88|\n",
    "|83000.0|         83|\n",
    "+-------+-----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# What occupation had the highest salary?\n",
    "df.orderBy(df[\"Salary\"].asc()).select(\"occupation\", \"Salary\", \"location\").limit(1).show()\n",
    "\n",
    "+-----------------+------+\n",
    "|       occupation|Salary|\n",
    "+-----------------+------+\n",
    "|Medical Physicist|    90|\n",
    "+-----------------+------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# What is the mean salary of this dataset? Import mean \n",
    "\n",
    "from pyspark.sql.functions import mean\n",
    "df.select(mean(\"Salary\")).show()\n",
    "\n",
    "+-----------+\n",
    "|avg(Salary)|\n",
    "+-----------+\n",
    "|     77.738|\n",
    "+-----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# What is the max and min of the Salary column?\n",
    "from pyspark.sql.functions import max, min\n",
    "df.select(max(\"Salary\"), min(\"Salary\")).show()\n",
    "\n",
    "+-----------+-----------+\n",
    "|max(Salary)|min(Salary)|\n",
    "+-----------+-----------+\n",
    "|         90|         65|\n",
    "+-----------+-----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "# Show all of the occupations where salaries were above 80k\n",
    "from pyspark.sql.functions import count\n",
    "df.filter(\"Salary > 80\").select(\"occupation\").head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
